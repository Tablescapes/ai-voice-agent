<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Interface</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .voice-container {
            background: white;
            padding: 40px;
            border-radius: 20px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            text-align: center;
            max-width: 600px;
            width: 100%;
        }
        .voice-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #ff6b6b, #ff8e8e);
            color: white;
            font-size: 24px;
            cursor: pointer;
            margin: 20px;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            justify-content: center;
        }
        .voice-button:hover {
            transform: scale(1.1);
            box-shadow: 0 5px 20px rgba(255, 107, 107, 0.4);
        }
        .voice-button.listening {
            background: linear-gradient(135deg, #4CAF50, #8BC34A);
            animation: pulse 1.5s infinite;
        }
        .voice-button.processing {
            background: linear-gradient(135deg, #FF9800, #FFC107);
            animation: spin 1s linear infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .status {
            margin: 20px 0;
            font-size: 18px;
            color: #333;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            min-height: 100px;
            text-align: left;
            font-family: monospace;
            white-space: pre-wrap;
        }
        .confidence {
            margin: 10px 0;
            font-size: 14px;
            color: #666;
        }
        .controls {
            margin: 20px 0;
        }
        .btn {
            background: #667eea;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
            text-decoration: none;
            display: inline-block;
        }
        .btn:hover {
            background: #5a6fd8;
        }
        .volume-indicator {
            width: 100%;
            height: 10px;
            background: #ddd;
            border-radius: 5px;
            margin: 10px 0;
            overflow: hidden;
        }
        .volume-level {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #FF9800, #f44336);
            width: 0%;
            transition: width 0.1s ease;
        }
    </style>
</head>
<body>
    <div class="voice-container">
        <h1>AI Voice Assistant</h1>
        <p>Click the microphone to start talking</p>
        
        <button id="voiceButton" class="voice-button" onclick="toggleVoice()">
            ðŸŽ¤
        </button>
        
        <div id="status" class="status">Ready to listen</div>
        
        <div class="volume-indicator">
            <div id="volumeLevel" class="volume-level"></div>
        </div>
        
        <div id="transcript" class="transcript">Conversation will appear here...</div>
        
        <div id="confidence" class="confidence"></div>
        
        <div class="controls">
            <button class="btn" onclick="clearTranscript()">Clear</button>
            <a href="/" class="btn">Back to Dashboard</a>
        </div>
        
        <audio id="responseAudio" controls style="display: none;"></audio>
    </div>

    <script>
        let isListening = false;
        let websocket = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let audioContext = null;
        let analyser = null;
        let microphone = null;

        async function initializeAudio() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                analyser.fftSize = 256;
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = sendAudioData;
                
                return true;
            } catch (error) {
                console.error('Error accessing microphone:', error);
                updateStatus('Error: Could not access microphone');
                return false;
            }
        }

        function updateVolumeIndicator() {
            if (!analyser) return;
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteFrequencyData(dataArray);
            
            let sum = 0;
            for (let i = 0; i < bufferLength; i++) {
                sum += dataArray[i];
            }
            const average = sum / bufferLength;
            const volumePercent = (average / 255) * 100;
            
            document.getElementById('volumeLevel').style.width = volumePercent + '%';
            
            if (isListening) {
                requestAnimationFrame(updateVolumeIndicator);
            }
        }

        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws/voice`;
            
            websocket = new WebSocket(wsUrl);
            
            websocket.onopen = () => {
                console.log('WebSocket connected');
            };
            
            websocket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                handleWebSocketMessage(data);
            };
            
            websocket.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Connection error');
            };
            
            websocket.onclose = () => {
                console.log('WebSocket disconnected');
                if (isListening) {
                    stopListening();
                }
            };
        }

        function handleWebSocketMessage(data) {
            if (data.type === 'response') {
                updateTranscript(`Agent: ${data.text}`);
                updateConfidence(data.confidence);
                
                if (data.audio) {
                    playAudioResponse(data.audio);
                }
                
                updateStatus('Ready to listen');
                updateVoiceButton('ready');
                
            } else if (data.type === 'transfer') {
                updateTranscript(`Agent: ${data.message}`);
                updateStatus('Transferring to human agent...');
                updateVoiceButton('ready');
            }
        }

        function playAudioResponse(audioBase64) {
            try {
                const audioBlob = base64ToBlob(audioBase64, 'audio/wav');
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = document.getElementById('responseAudio');
                audio.src = audioUrl;
                audio.play();
            } catch (error) {
                console.error('Error playing audio response:', error);
            }
        }

        function base64ToBlob(base64, mimeType) {
            const byteCharacters = atob(base64);
            const byteNumbers = new Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
                byteNumbers[i] = byteCharacters.charCodeAt(i);
            }
            const byteArray = new Uint8Array(byteNumbers);
            return new Blob([byteArray], {type: mimeType});
        }

        async function toggleVoice() {
            if (!isListening) {
                startListening();
            } else {
                stopListening();
            }
        }

        async function startListening() {
            if (!mediaRecorder) {
                const initialized = await initializeAudio();
                if (!initialized) return;
            }
            
            if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                connectWebSocket();
                await new Promise(resolve => {
                    const checkConnection = () => {
                        if (websocket && websocket.readyState === WebSocket.OPEN) {
                            resolve();
                        } else {
                            setTimeout(checkConnection, 100);
                        }
                    };
                    checkConnection();
                });
            }
            
            isListening = true;
            audioChunks = [];
            
            updateStatus('Listening...');
            updateVoiceButton('listening');
            updateVolumeIndicator();
            
            mediaRecorder.start();
            
            setTimeout(() => {
                if (isListening) {
                    stopListening();
                }
            }, 10000);
        }

        function stopListening() {
            if (!isListening) return;
            
            isListening = false;
            updateStatus('Processing...');
            updateVoiceButton('processing');
            
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }

        async function sendAudioData() {
            if (audioChunks.length === 0) return;
            
            try {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
                const arrayBuffer = await audioBlob.arrayBuffer();
                
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(arrayBuffer);
                    updateTranscript(`User: [Speaking...]`);
                } else {
                    updateStatus('Connection error - please try again');
                    updateVoiceButton('ready');
                }
            } catch (error) {
                console.error('Error sending audio:', error);
                updateStatus('Error sending audio');
                updateVoiceButton('ready');
            }
        }

        function updateStatus(message) {
            document.getElementById('status').textContent = message;
        }

        function updateVoiceButton(state) {
            const button = document.getElementById('voiceButton');
            button.className = 'voice-button';
            
            switch(state) {
                case 'listening':
                    button.classList.add('listening');
                    button.textContent = 'ðŸ”´';
                    break;
                case 'processing':
                    button.classList.add('processing');
                    button.textContent = 'âš™ï¸';
                    break;
                default:
                    button.textContent = 'ðŸŽ¤';
            }
        }

        function updateTranscript(text) {
            const transcript = document.getElementById('transcript');
            transcript.textContent += text + '\n';
            transcript.scrollTop = transcript.scrollHeight;
        }

        function updateConfidence(confidence) {
            const confidenceElement = document.getElementById('confidence');
            const percentage = Math.round(confidence * 100);
            confidenceElement.textContent = `Confidence: ${percentage}%`;
            
            if (confidence > 0.8) {
                confidenceElement.style.color = '#4CAF50';
            } else if (confidence > 0.6) {
                confidenceElement.style.color = '#FF9800';
            } else {
                confidenceElement.style.color = '#f44336';
            }
        }

        function clearTranscript() {
            document.getElementById('transcript').textContent = 'Conversation will appear here...';
            document.getElementById('confidence').textContent = '';
        }

        window.addEventListener('load', () => {
            updateStatus('Click microphone to start');
        });

        window.addEventListener('beforeunload', () => {
            if (websocket) {
                websocket.close();
            }
        });
    </script>
</body>
</html>
